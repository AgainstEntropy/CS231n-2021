{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "写一些东西，方便理解如何求SVM的hinge_LOSS和权重矩阵$W$的梯度$dW$。\n",
    "\n",
    "假设我们共有10张图片，被分为3类。\n",
    "用$X_i$(`imgs[i](i=1,2,...,10)`)表示第$i$张图片的所有像素，$y_i$(`label[i]`)表示第$i$张图片对应的类别标签（`label[i]=0,1,2`）。\n",
    "假设每张图片的长和宽都为2个像素，有3个通道（$\\color{red}{R}\\color{green}{G}\\color{blue}{B}$）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前2张图片是：\n",
      " [[[[0.44610755 0.50850947 0.06605838]\n",
      "   [0.46162918 0.19888073 0.57064383]]\n",
      "\n",
      "  [[0.98715871 0.42333655 0.69537932]\n",
      "   [0.23180493 0.3750864  0.04938028]]]\n",
      "\n",
      "\n",
      " [[[0.07719142 0.32079032 0.66292269]\n",
      "   [0.00509739 0.41437673 0.91452219]]\n",
      "\n",
      "  [[0.60394883 0.72229577 0.3316002 ]\n",
      "   [0.59225726 0.54067025 0.19174882]]]]\n",
      "\n",
      "所有图片的标签是：\n",
      " [2 1 0 2 1 2 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "imgs = np.random.rand(10, 2, 2, 3)\n",
    "label = np.random.randint(0, 3, size=10)\n",
    "img_test = np.random.rand(2, 2, 2, 3)\n",
    "\n",
    "print(\"前2张图片是：\\n\", imgs[:2])\n",
    "print(\"\\n所有图片的标签是：\\n\", label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了方便后续处理，将每张图片reshape为长度为$2\\times2\\times3 = 12$的向量，\n",
    "并且添加一个1在矢量末尾作为偏置维度（bias dimension），因此图片空间的维度$D=12+1=13$。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的前2张图片是：\n",
      " [[0.44610755 0.50850947 0.06605838 0.46162918 0.19888073 0.57064383\n",
      "  0.98715871 0.42333655 0.69537932 0.23180493 0.3750864  0.04938028\n",
      "  1.        ]\n",
      " [0.07719142 0.32079032 0.66292269 0.00509739 0.41437673 0.91452219\n",
      "  0.60394883 0.72229577 0.3316002  0.59225726 0.54067025 0.19174882\n",
      "  1.        ]]\n",
      "\n",
      "共有10张图片，每张图片的维度是13。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imgs = imgs.reshape(10, -1)\n",
    "imgs = np.hstack([imgs, np.ones((imgs.shape[0], 1))])\n",
    "\n",
    "print(\"处理后的前2张图片是：\\n\", imgs[:2])\n",
    "print(\"\\n共有%d张图片，每张图片的维度是%d。\\n\"%imgs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了对图片做分类，SVM的想法是用一个$13\\times 3$维的线性变换$W$将图片向量$X_i$从图片空间（13维）映射到类别空间（3维），\n",
    "若将线性变换后的向量记作$S_i$，则$S_i$在某一维度$j$上的分量$S_{ij}$即为第$i$张图片在第$j$类上的得分。\n",
    "一个朴素的想法是，得分$S_{ij}$越高，就代表着第$i$张图片越应该被分在第$j$类。\n",
    "\n",
    "我们已知第i张图片的分类$y_i$，因此可以将$S_{iy_i}$和$S_{ij}(j\\neq y_i)$作差进行比较，\n",
    "并且设定一个所谓的“安全距离”$\\Delta$——当$S_{iy_i} - S_{ij}(j\\neq y_i) \\ge \\Delta$时，\n",
    "我们就可以认为相比于第$j$类，第$i$张图片已经被足够好地分在了第$y_i$类，\n",
    "即“分类足够正确”。因此可以写出第$i$张图片的损失函数：\n",
    "\n",
    "$$L_i = \\sum_{j\\neq y_i}\\max(0,\\ S_{ij} - S_{iy_i} + \\Delta) = \\sum_{j\\neq y_i}\\max(0,\\ (W^T)_j \\cdot X_i - (W^T)_{y_i} \\cdot X_i + \\Delta)$$\n",
    "\n",
    "根据上述定义和运算，$W$的第$j$列对应着分到第$j$类的权重，$S_{ij} = (W^T)_j \\cdot X_i$，即$W_{nj}$本质上代表着任何一张图片的第$n$个像素点对于将这张图片分为第$j$类的贡献（权重）。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 随机初始化一个权重矩阵W\n",
    "W = np.random.randn(13, 3)\n",
    "S = np.dot(imgs, W)\n",
    "\n",
    "print(\"W是一个%d*%d维矩阵\\n\"%W.shape, W)\n",
    "print(\"\\nS是一个%d*%d维矩阵\\n\"%S.shape, S)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W是一个13*3维矩阵\n",
      " [[ 0.38922976 -1.5476645   0.29391136]\n",
      " [ 1.88278845 -2.03980096  0.87708064]\n",
      " [ 0.6370439   1.20157172 -1.41819386]\n",
      " [-0.72895385  1.54486262 -0.13406272]\n",
      " [-1.0054797  -0.87397261  0.97254715]\n",
      " [ 1.4744262  -0.09882989  0.06366316]\n",
      " [ 1.07822844  1.34769706  1.57454748]\n",
      " [ 0.11163696 -1.39929385 -0.46959958]\n",
      " [ 1.61945353 -0.25428393 -1.06335361]\n",
      " [ 0.19482573  0.42195421  0.34891287]\n",
      " [ 1.51212699 -2.70581067 -0.03097324]\n",
      " [ 0.78342346  0.2109576   0.17596721]\n",
      " [-0.38857257  0.52356264 -0.07280062]]\n",
      "\n",
      "S是一个10*3维矩阵\n",
      " [[ 3.9782615  -0.98729542  1.27254517]\n",
      " [ 3.94780649 -1.3520439   0.23442124]\n",
      " [ 4.75273802 -0.32327394 -1.08898947]\n",
      " [ 5.24844741 -1.91383568  1.44559066]\n",
      " [ 4.39185774 -0.42945789  1.34646468]\n",
      " [ 4.64370727 -2.85630203  0.36418856]\n",
      " [ 3.67487502 -2.61126693 -0.97194457]\n",
      " [ 2.64962175 -1.43415149  0.23078515]\n",
      " [ 2.69766682 -1.9465858  -0.15695445]\n",
      " [ 1.8519816   0.27556944  0.24302435]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了求出第$i$张图片的损失函数$L_i$，首先从得分矩阵$S$中挑出所有真实分类的得分，将其延展为与$S$相同的维度，\n",
    "与得分矩阵$S$作差后加上$\\Delta$即可得到（未经处理的）$L$矩阵："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_scores:\n",
      " [[ 1.27254517]\n",
      " [-1.3520439 ]\n",
      " [ 4.75273802]\n",
      " [ 1.44559066]\n",
      " [-0.42945789]\n",
      " [ 0.36418856]\n",
      " [-0.97194457]\n",
      " [ 0.23078515]\n",
      " [-1.9465858 ]\n",
      " [ 0.27556944]]\n",
      "\n",
      " [[ 1.27254517  1.27254517  1.27254517]\n",
      " [-1.3520439  -1.3520439  -1.3520439 ]\n",
      " [ 4.75273802  4.75273802  4.75273802]\n",
      " [ 1.44559066  1.44559066  1.44559066]\n",
      " [-0.42945789 -0.42945789 -0.42945789]\n",
      " [ 0.36418856  0.36418856  0.36418856]\n",
      " [-0.97194457 -0.97194457 -0.97194457]\n",
      " [ 0.23078515  0.23078515  0.23078515]\n",
      " [-1.9465858  -1.9465858  -1.9465858 ]\n",
      " [ 0.27556944  0.27556944  0.27556944]]\n",
      "\n",
      "L:\n",
      " [[ 3.70571632 -1.25984059  1.        ]\n",
      " [ 6.2998504   1.          2.58646514]\n",
      " [ 1.         -4.07601195 -4.84172749]\n",
      " [ 4.80285675 -2.35942634  1.        ]\n",
      " [ 5.82131563  1.          2.77592256]\n",
      " [ 5.27951872 -2.22049058  1.        ]\n",
      " [ 5.64681958 -0.63932236  1.        ]\n",
      " [ 3.41883661 -0.66493664  1.        ]\n",
      " [ 5.64425262  1.          2.78963135]\n",
      " [ 2.57641216  1.          0.96745491]]\n",
      "\n",
      "labels: [2 1 0 2 1 2 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "correct_scores = S[range(S.shape[0]), label].reshape(-1,1)\n",
    "print(\"correct_scores:\\n\", correct_scores)\n",
    "correct_scores = np.hstack([correct_scores] * S.shape[1])\n",
    "print(\"\\n\", correct_scores)\n",
    "Delta = 1  # 一个相对任意选择的“安全距离”\n",
    "L = S - correct_scores + Delta\n",
    "print(\"\\nL:\\n\", L)\n",
    "print(\"\\nlabels:\", label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到$L$矩阵中出现了很多$1$，这些$1$出现的位置正是每张图片的正确分类位置，\n",
    "即$L_{iy_i} = \\Delta (= 1)$。根据$L_i$的定义，我们还需要做两步操作：\n",
    "\n",
    "1. 将每个图片的正确分类位置置零，因为公式中并不包含这一项；\n",
    "2. 将小于零的位置置零，因为公式中的$\\max(0, blabla)$保证了这一点。\n",
    "\n",
    "我们使用一个蒙版`mask`来实现这两步处理，而不直接修改$L$本身。\n",
    "\n",
    "（注：使用`mask`的好处将在计算梯度$dW$时得以体现。）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask = \n",
      " [[1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]]\n",
      "\n",
      "L = \n",
      " [[ 3.70571632 -0.          0.        ]\n",
      " [ 6.2998504   0.          2.58646514]\n",
      " [ 0.         -0.         -0.        ]\n",
      " [ 4.80285675 -0.          0.        ]\n",
      " [ 5.82131563  0.          2.77592256]\n",
      " [ 5.27951872 -0.          0.        ]\n",
      " [ 5.64681958 -0.          0.        ]\n",
      " [ 3.41883661 -0.          0.        ]\n",
      " [ 5.64425262  0.          2.78963135]\n",
      " [ 2.57641216  0.          0.96745491]]\n"
     ]
    }
   ],
   "source": [
    "mask = np.ones(L.shape)\n",
    "mask[range(L.shape[0]), label] = 0  # 正确分类位置置零\n",
    "mask[L < 0] = 0  # 小于零的位置置零\n",
    "L *= mask\n",
    "\n",
    "print(\"mask = \\n\", mask)\n",
    "print(\"\\nL = \\n\", L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "经过处理的$L$中仍不为0的位置实际上就是分类结果不够好的位置，数字越大就代表分类结果越差；\n",
    "反之，若第i行的数字全为0，则代表当前的$W$不仅对于第i张图片的分类是正确的，\n",
    "并且将其他图片拒于“安全距离”以外。\n",
    "\n",
    "现在，$L$的第i行数字之和即为$L_i$，矩阵中所有数字之和即为总的损失函数$L$："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.70571632 8.88631554 0.         4.80285675 8.59723819 5.27951872\n",
      " 5.64681958 3.41883661 8.43388397 3.54386707]\n"
     ]
    },
    {
     "data": {
      "text/plain": "5.231505276181342"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.sum(L, axis=1)\n",
    "print(\"L = \", L)\n",
    "loss = np.sum(L) / len(L)\n",
    "print(\"\\nloss = \", loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "试想，如果将$W$扩大$\\alpha$倍，那么除了损失函数也相应地扩大$\\alpha$倍以外，不会再有其他影响。\n",
    "由此，我们可以为损失函数添加正则惩罚(regularization penalty)，这其中蕴含着奥卡姆剃刀的思想，\n",
    "即鼓励简化、鼓励稀疏、反对不必要的复杂，这同时也能一定程度上防止过拟合。\n",
    "公式中的$\\lambda$是正则惩罚的力度，$\\sum_k\\sum_l W_{k,l}^2$是当前的$W$与零矩阵的Frobenius范数，\n",
    "用来定量评估两者的差异。\n",
    "\n",
    "加入正则惩罚的总损失函数为：\n",
    "\n",
    "$$L = \\frac{1}{N} \\sum_i \\sum_{j\\neq y_i} \\left[ \\max(0,\\ (X_i\\cdot W)_j - (X_i\\cdot W)_{y_i} + \\Delta) \\right] + \\lambda \\sum_k\\sum_l W_{k,l}^2\\\\$$\n",
    "\n",
    "将上面的步骤进行整合就可以写出完整的`svm_loss`函数："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def svm_loss(W, X, y, delta, reg):\n",
    "    \"\"\"\n",
    "    SVM loss function, vectorized implementation.\n",
    "\n",
    "    Input images have dimension D, there are C classes, and we operate on N examples.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - delta: (float) classification safe margin\n",
    "    - reg: (float) regularization strength\n",
    "\n",
    "    Return:\n",
    "    - loss as single float\n",
    "    \"\"\"\n",
    "\n",
    "    S = np.dot(X, W)\n",
    "    correct_scores = S[range(S.shape[0]), y].reshape(-1,1)\n",
    "    correct_scores = np.hstack([correct_scores] * S.shape[1])\n",
    "\n",
    "    L = S - correct_scores + delta\n",
    "\n",
    "    mask = np.ones(L.shape)\n",
    "    mask[range(L.shape[0]), y] = 0  # 正确分类位置置零\n",
    "    mask[L < 0] = 0  # 小于零的位置置零\n",
    "    L *= mask\n",
    "\n",
    "    loss = np.sum(L) / len(L)\n",
    "    loss += reg * np.sum(W * W)\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  5.458238730215393\n"
     ]
    }
   ],
   "source": [
    "loss = svm_loss(W, imgs, label, delta=1, reg=0.005)\n",
    "print(\"loss = \", loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "现在来计算梯度矩阵$dW$。根据梯度的定义，$dW$具有如下原始形式：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{W} L\n",
    "    :=\n",
    "    \\begin{bmatrix}\n",
    "        \\frac{dL}{dW_{11}} & \\frac{dL}{dW_{12}} & \\cdots & \\frac{dL}{dW_{1C}} \\\\\n",
    "        \\frac{dL}{dW_{21}} & \\frac{dL}{dW_{22}} & \\cdots & \\frac{dL}{dW_{2C}} \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "        \\frac{dL}{dW_{D1}} & \\frac{dL}{dW_{D2}} & \\cdots & \\frac{dL}{dW_{DC}}\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "在本例中，图片数量为$N=10$，图片空间维度$D=13$，类别数$C=3$。由于上面的数据是随机生成的，\n",
    "故每次运行程序所得的`mask`也不同。现在以下面给定的`mask`为例做一些分析，为后续的向量化计算$dW$捋清思路。\n",
    "为了简明，只分析`mask`的前两行。\n",
    "\n",
    "\\begin{equation}\n",
    "    mask\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        \\color{red}{0} & 1 & 1 \\\\\n",
    "        1 & \\color{green}{0} & \\color{red}{0} \\\\\n",
    "        \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "这里红色的$\\color{red}{0}$代表因为分类正确而置零，绿色的$\\color{green}{0}$代表因为小于零而置零（参考上面的分析）。\n",
    "现在以这个`mask`为例分析梯度$dW$中的几个元素。先写出$L_1$最终的表达式：\n",
    "\n",
    "$$L_1 = (S_{12} - S_{11} + \\Delta) + (S_{13} - S_{11} + \\Delta)$$\n",
    "\n",
    "利用链式法则可以得到\n",
    "\n",
    "$$\\frac{\\partial L_1}{\\partial W_{11}} = \\sum_j \\frac{\\partial L_1}{\\partial S_{1j}} \\frac{\\partial S_{1j}}{\\partial W_{11}} = (-2) X_{11}$$\n",
    "\n",
    "同理，\n",
    "$$\\frac{\\partial L_1}{\\partial W_{n1}} = \\sum_j \\frac{\\partial L_1}{\\partial S_{1j}} \\frac{\\partial S_{1j}}{\\partial W_{n1}} = (-2) X_{1n}$$\n",
    "\n",
    "这里的系数$-2$来自于`mask`中第一行有2个1，其中的负号是因为$W$的第二个下标1正好对应第一张图片的正确分类标签$y_1 = 0$\n",
    "（注：此处的图片被分为三类，即$\\{1,2,3\\}$，对应分类的标签$\\{0,1,2\\}$），从而$S_{11}$出现在公式里的负号后。\n",
    "因此$L_1$对$dW$的第1列贡献了$-2$个$X_1$\n",
    "\n",
    "再看另一个元素：\n",
    "\n",
    "$$\\frac{\\partial L_1}{\\partial W_{12}} = \\sum_j \\frac{\\partial L_1}{\\partial S_{1j}} \\frac{\\partial S_{1j}}{\\partial W_{12}} = X_{11}$$\n",
    "\n",
    "同理，$$\\frac{\\partial L_1}{\\partial W_{n2}} = \\sum_j \\frac{\\partial L_1}{\\partial S_{1j}} \\frac{\\partial S_{1j}}{\\partial W_{n2}} = X_{1n} \\ ,\\ \\frac{\\partial L_1}{\\partial W_{n3}} = \\sum_j \\frac{\\partial L_1}{\\partial S_{1j}} \\frac{\\partial S_{1j}}{\\partial W_{n3}} = X_{1n}$$\n",
    "\n",
    "与上面的分析类同，$L_1$对$dW$的第2列和第3列分别贡献了1个$X_1$。将目前已经分析过的部分写成更简练的矩阵形式：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{W} L_1\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        X_1 & X_2 & \\cdots & X_N\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        \\color{red}{-2} & 1 & 1 \\\\\n",
    "        0 & 0 & 0 \\\\\n",
    "        \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    X^T mask_1\n",
    "\\end{equation}\n",
    "\n",
    "接下来分析$L_2$，与$L_1$完全类同，但由于$L_2 = (S_{21} - S_{23} + \\Delta)$，\n",
    "$L_2$对$dW$的第1列贡献了1个$X_1$，第3列贡献了-1个$X_1$，写进矩阵即为：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{W} L_2\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        X_1 & X_2 & \\cdots & X_N\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    X^T \\begin{bmatrix}\n",
    "        0 & 0 & 0 \\\\\n",
    "        1 & \\color{green}{0} & \\color{red}{-1} \\\\\n",
    "        0 & 0 & 0 \\\\\n",
    "        \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "将$mask_1,mask_2$与$mask$对比可知，$mask_i$就是将$mask$的第$i$行单独取出，\n",
    "在红色位置（即第$i$张图片的正确分类位置）上填入$mask$的第$i$行之和的相反数。\n",
    "最终完整的$dW$矢量化计算公式为：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{W} L\n",
    "    =\n",
    "    \\sum_{i=1}^N \\nabla_{W} L_i\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        X_1 & X_2 & \\cdots & X_N\n",
    "    \\end{bmatrix}\n",
    "    \\sum_{i=1}^N mask_i\n",
    "    =\n",
    "    X^T\n",
    "    \\begin{bmatrix}\n",
    "        \\color{red}{-2} & 1 & 1 \\\\\n",
    "        1 & \\color{green}{0} & \\color{red}{-1} \\\\\n",
    "        \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "还要加入正则化惩罚：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nabla_{W} L\n",
    "    =\n",
    "    \\frac{1}{N} X^T\n",
    "    \\begin{bmatrix}\n",
    "        \\color{red}{-2} & 1 & 1 \\\\\n",
    "        1 & \\color{green}{0} & \\color{red}{-1} \\\\\n",
    "        \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\end{bmatrix} + 2\\lambda W\n",
    "\\end{equation}\n",
    "\n",
    "由此可以写出完整的代码："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def svm_loss_grad(W, X, y, delta, reg):\n",
    "    \"\"\"\n",
    "    Structured SVM loss function, vectorized implementation.\n",
    "\n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - delta: (float) classification safe margin\n",
    "    - reg: (float) regularization strength\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape)  # initialize the gradient as zero\n",
    "\n",
    "    # A vectorized version of the structured SVM loss and gradient.\n",
    "    S = np.dot(X, W)\n",
    "    correct_scores = S[range(S.shape[0]), y].reshape(-1,1)\n",
    "\n",
    "    # 利用numpy的broadcast特性可以省略下面这行代码\n",
    "    # correct_scores = np.hstack([correct_scores] * S.shape[1])\n",
    "\n",
    "    L = S - correct_scores + delta\n",
    "\n",
    "    mask = np.ones(L.shape)\n",
    "    mask[range(L.shape[0]), y] = 0  # 正确分类位置置零\n",
    "    mask[L < 0] = 0  # 小于零的位置置零\n",
    "    L *= mask\n",
    "\n",
    "    loss += np.sum(L) / X.shape[0]\n",
    "    loss += reg * np.sum(W * W)\n",
    "\n",
    "    dW += np.dot(X.T, mask) / X.shape[0]  # D*C = D*N dot N*C\n",
    "    dW += 2 * reg * W\n",
    "\n",
    "    return loss, dW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(7.457803289988815,\n array([[-0.06685351, -0.08443495, -0.04007769],\n        [-0.03463011, -0.05389141, -0.02550633],\n        [-0.03927926, -0.04445769, -0.06018695],\n        [-0.05720121, -0.04758712, -0.06605697],\n        [-0.04060118, -0.02268876, -0.03123908],\n        [-0.05290632, -0.05539774, -0.06639562],\n        [-0.04763426, -0.04088936, -0.0429609 ],\n        [-0.05755835, -0.06501836, -0.04997568],\n        [-0.05682862, -0.08448008, -0.08736774],\n        [-0.06769446, -0.04170579, -0.06186615],\n        [-0.05542174, -0.07509581, -0.06060786],\n        [-0.04871209, -0.05045147, -0.05053867],\n        [-0.12712141, -0.09735306, -0.10617105]]))"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, dW = svm_loss_grad(W, imgs, label, delta=1, reg=0.005)\n",
    "loss, dW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 20  # 图片数量\n",
    "C = 4   # 分类数量\n",
    "D = 3   # 图片尺寸\n",
    "# 随机初始化\n",
    "imgs = np.random.rand(N, D, D, 3)\n",
    "label = np.random.randint(0, C, size=N)\n",
    "\n",
    "imgs = imgs.reshape(N, -1)\n",
    "imgs = np.hstack([imgs, np.ones((imgs.shape[0], 1))])\n",
    "W = np.random.randn(imgs.shape[1], C)\n",
    "\n",
    "loss_list, correct_rate_list = [], []\n",
    "T = np.arange(200)  # 训练次数\n",
    "alpha = 0.2         # 学习率（步长）\n",
    "delta = 1           # 安全距离\n",
    "reg = 5e-5          # 正则惩罚强度\n",
    "\n",
    "for t in T:\n",
    "    loss, dW = svm_loss_grad(W, imgs, label, delta=delta, reg=reg)\n",
    "    W -= alpha * dW\n",
    "\n",
    "    scores = np.dot(imgs, W)\n",
    "    label_pred = np.argmax(scores, axis=1)\n",
    "    correct_rate = np.sum(label_pred == label) / len(label)\n",
    "\n",
    "    loss_list.append(loss)\n",
    "    correct_rate_list.append(correct_rate)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(T, loss_list)\n",
    "plt.title(\"loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(T, correct_rate_list)\n",
    "plt.title(\"correct_rate\")\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}